{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2    \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "import shutil\n",
    "from othello_environment_gym.othello_environment import OthelloEnv,make_random_policy\n",
    "from gym.envs.board_game.go import GoEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_output(params, obs):\n",
    "\n",
    "  weights = tf.slice(params, [0], [36])\n",
    "  obs_reshaped = tf.reshape(obs, [-1, 36])\n",
    "  bias = params[-1]\n",
    "  #obs2 = tf.Print(obs_reshaped, [tf.shape(obs_reshaped), tf.shape(weights), tf.shape(tf.mul(obs_reshaped, weights))], message=\"obs shape\")\n",
    "  activation = tf.reduce_sum(tf.mul(obs_reshaped, weights), 1) + bias\n",
    "  #activation2 = tf.Print(activation, [activation, tf.shape(activation)], message=\"activation\")\n",
    "  return tf.sigmoid(activation)  # probability of choosing move 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_get_output(sess):\n",
    "  from math import exp\n",
    "  def sigmoid(x): return 1./(1. + exp(-x))\n",
    "  \n",
    "  params = [1., 2., 3., 4., 5.]\n",
    "  obs = [0.4, 6., 8., 5.]\n",
    "  activation = 0.4 + 12 + 24 + 20 + 5\n",
    "  output = sess.run(get_output(params, obs))\n",
    "  print(output, [sigmoid(activation)])\n",
    "  assert abs(output - [sigmoid(activation)]) < 1e-6\n",
    "  \n",
    "  obs = [[0.4, 6., -3., 5.], [0.8, -0.5, 0.6, -0.01]]\n",
    "  activation = [0.4 + 12 - 9 + 20 + 5, 0.8 - 1. + 1.8 - 0.04 +5]\n",
    "  after_activ = map(sigmoid, activation)\n",
    "  output = sess.run(get_output(params, obs))\n",
    "  assert abs(sum(output - after_activ)) < 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_action(output):\n",
    "  probs = tf.transpose(tf.pack([output, 1. - output]))\n",
    "  return tf.reshape(tf.multinomial(tf.log(probs), 1), [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_get_action(sess):\n",
    "  output = [0.99, 0.001, 0.001]\n",
    "  actions = sess.run(get_action(tf.convert_to_tensor(output)))\n",
    "  print(actions)\n",
    "  assert (actions == [0, 1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_loss(output, actions, reward, average_reward, num_moves):\n",
    "  eps =  1e-16\n",
    "  #output2 = tf.Print(output, [output, tf.shape(output), tf.shape(actions)], message=\"output\")\n",
    "  pred = tf.equal(actions, 0)\n",
    "  move_ids = tf.cast(tf.range(num_moves), tf.float32)\n",
    "  \n",
    "  select = tf.select(pred, tf.log(output + eps), tf.log(1. + eps - output))\n",
    "  #select2 = tf.Print(select, [select, average_reward], message=\"select\")\n",
    "  advantage = (reward - average_reward) - move_ids\n",
    "  #advantage2 = tf.Print(advantage, [advantage], message=\"advantage\")\n",
    "  return tf.reduce_sum(tf.mul(advantage, select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_loss(sess):\n",
    "  from math import log\n",
    "  outputs = [0.55, 0.7, 0.1]  # probabilities of choosing 0\n",
    "  actions = [0, 1, 0]\n",
    "  log_probs = [log(0.55), log(0.3), log(0.1)]\n",
    "  reward = 4.\n",
    "  num_moves = len(outputs)\n",
    "  \n",
    "  my_loss = sess.run(get_loss(outputs, actions, reward, num_moves))\n",
    "  print(my_loss, reward * np.sum(log_probs))\n",
    "  assert abs(my_loss - reward * np.sum(log_probs)) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_model(params, output, obs_place, action, render=False):\n",
    "  env.reset()\n",
    "  print(env.action_space.n)\n",
    "#   assert env.action_space.n == 16\n",
    "  first_action = env.action_space.sample()\n",
    "  obs, rew, done, _ = env.step(first_action)\n",
    "  reward = rew\n",
    "  observations = []\n",
    "  actions = []\n",
    "  while not done:\n",
    "    if reward >= 1000:\n",
    "      break\n",
    "    if render:\n",
    "      env.render()\n",
    "    action_eval = sess.run(action, feed_dict={obs_place: obs})[0]\n",
    "    observations.append(obs)\n",
    "    actions.append(action_eval)\n",
    "    \n",
    "    obs, rew, done, _ = env.step(action_eval)\n",
    "    reward += rew\n",
    "  env.close()\n",
    "  return (reward, np.vstack(observations), actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_session():\n",
    "  config = tf.ConfigProto(operation_timeout_in_ms=5000)\n",
    "  return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Inputs to operation Select of type Select must have the same size and shape.  Input 0: [3] != input 1: [9]\n\t [[Node: Select = Select[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal, Log_1, Log_2)]]\n\nCaused by op u'Select', defined at:\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-113-685a3c5620a9>\", line 29, in <module>\n    loss = get_loss(output, action_place, reward_place, average_place, num_moves_place)\n  File \"<ipython-input-109-e1c4ea414d07>\", line 7, in get_loss\n    select = tf.select(pred, tf.log(output + eps), tf.log(1. + eps - output))\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1979, in select\n    name=name)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Inputs to operation Select of type Select must have the same size and shape.  Input 0: [3] != input 1: [9]\n\t [[Node: Select = Select[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal, Log_1, Log_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-685a3c5620a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                                      feed_dict={observation_place: observations, action_place: actions,\n\u001b[1;32m     47\u001b[0m                                                 \u001b[0mreward_place\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_place\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum_rewards\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                                                 num_moves_place: observations.shape[0]})\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m#print(\"reward:\", rew, \"\\nobservations: \", observations, \"\\nobs sum:\", np.sum(observations, axis=0),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#      \"\\nactions:\", actions, \"\\ngradients:\", loss_grad_ev)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inputs to operation Select of type Select must have the same size and shape.  Input 0: [3] != input 1: [9]\n\t [[Node: Select = Select[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal, Log_1, Log_2)]]\n\nCaused by op u'Select', defined at:\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-113-685a3c5620a9>\", line 29, in <module>\n    loss = get_loss(output, action_place, reward_place, average_place, num_moves_place)\n  File \"<ipython-input-109-e1c4ea414d07>\", line 7, in get_loss\n    select = tf.select(pred, tf.log(output + eps), tf.log(1. + eps - output))\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1979, in select\n    name=name)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/jakub/anaconda2/envs/tensorflow_2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Inputs to operation Select of type Select must have the same size and shape.  Input 0: [3] != input 1: [9]\n\t [[Node: Select = Select[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Equal, Log_1, Log_2)]]\n"
     ]
    }
   ],
   "source": [
    "env = GoEnv(player_color = \"white\",\n",
    "                 opponent = \"random\",\n",
    "                 observation_type = \"image3c\",\n",
    "                 illegal_move_mode = \"lose\",\n",
    "                 board_size = 6\n",
    "                )   \n",
    "\n",
    "# observation = env.reset()\n",
    "# for _ in range(20):\n",
    "#   env.render()\n",
    "#   action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "#   observation, reward, done, info = env.step(action)\n",
    "\n",
    "rounds=5000\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with get_session() as sess:\n",
    "  theta = tf.Variable([0.] * 6, dtype=tf.float32, name=\"theta\")\n",
    "  observation_place = tf.placeholder(tf.float32, shape=None)\n",
    "  action_place = tf.placeholder(tf.float32, shape=None)\n",
    "  reward_place = tf.placeholder(tf.float32, shape=None)\n",
    "  num_moves_place = tf.placeholder(tf.int32, shape=None)\n",
    "  average_place = tf.placeholder(tf.float32, shape=None)\n",
    "  \n",
    "  output = get_output(theta, observation_place)\n",
    "  action = get_action(output)\n",
    "  \n",
    "  loss = get_loss(output, action_place, reward_place, average_place, num_moves_place)\n",
    "  loss_grad = tf.gradients(loss, [theta])[0]\n",
    "  learning_rate = 0.0001\n",
    "  gradient_place = tf.placeholder(tf.float32, shape=None)\n",
    "  \n",
    "  params_update_op = tf.assign_add(theta, gradient_place)\n",
    "  \n",
    "  sess.run(tf.initialize_all_variables())\n",
    "  \n",
    "  sum_rewards = 0.\n",
    "  #test_get_action(sess)\n",
    "  #test_get_output(sess)\n",
    "  for i in range(rounds):\n",
    "    #print(\"theta:\", sess.run(theta))\n",
    "    rew, observations, actions = run_model(theta, output, observation_place, action)\n",
    "    sum_rewards += rew\n",
    "    loss_ev, loss_grad_ev = sess.run([loss, loss_grad],\n",
    "                                     feed_dict={observation_place: observations, action_place: actions,\n",
    "                                                reward_place: rew, average_place: min(100., (sum_rewards / (i+1))),\n",
    "                                                num_moves_place: observations.shape[0]})\n",
    "    #print(\"reward:\", rew, \"\\nobservations: \", observations, \"\\nobs sum:\", np.sum(observations, axis=0),\n",
    "    #      \"\\nactions:\", actions, \"\\ngradients:\", loss_grad_ev)\n",
    "    sess.run(params_update_op, feed_dict={gradient_place: loss_grad_ev * learning_rate})\n",
    "    print(i, rew)\n",
    "    prev = rew\n",
    "  shutil.rmtree(\"/tmp/pg1\")\n",
    "  writer = tf.train.SummaryWriter(\"/tmp/pg1\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
